{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# dalle-mega\n",
    "DALLE_MODEL = \"../datasets/dalle-mini-models/dallebart\"  \n",
    "DALLE_COMMIT_ID = None\n",
    "\n",
    "# DALLE_MODEL = \"dalle-mini/dalle-mini/mini-1:v0\"\n",
    "\n",
    "# VQGAN model\n",
    "VQGAN_REPO = \"../datasets/dalle-mini-models/vqgan-jax\"\n",
    "VQGAN_COMMIT_ID = \"e93a26e7707683d349bf5d5c41c5b0ef69b677a9\"\n",
    "\n",
    "DALLE_MODEL = \"dalle-mini/dalle-mini/mega-1-fp16:latest\" \n",
    "DALLE_COMMIT_ID = None\n",
    "\n",
    "# DALLE_MODEL = \"dalle-mini/dalle-mini/mini-1:v0\"\n",
    "\n",
    "# VQGAN model\n",
    "VQGAN_REPO = \"dalle-mini/vqgan_imagenet_f16_16384\"\n",
    "VQGAN_COMMIT_ID = \"e93a26e7707683d349bf5d5c41c5b0ef69b677a9\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress as IProgress\n",
    "from dalle_mini import DalleBart, DalleBartProcessor\n",
    "from vqgan_jax.modeling_flax_vqgan import VQModel\n",
    "from transformers import CLIPProcessor, FlaxCLIPModel\n",
    "\n",
    "\n",
    "# utils.logging.disable_progress_bar()\n",
    "# Load dalle-mini\n",
    "model, params = DalleBart.from_pretrained(\n",
    "    DALLE_MODEL, revision=DALLE_COMMIT_ID, dtype=jnp.float16, _do_init=False\n",
    ")\n",
    "\n",
    "# Load VQGAN\n",
    "vqgan, vqgan_params = VQModel.from_pretrained(\n",
    "    VQGAN_REPO, revision=VQGAN_COMMIT_ID, _do_init=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.jax_utils import replicate\n",
    "\n",
    "params = replicate(params)\n",
    "vqgan_params = replicate(vqgan_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# model inference\n",
    "@partial(jax.pmap, axis_name=\"batch\", static_broadcasted_argnums=(3, 4, 5, 6))\n",
    "def p_generate(\n",
    "    tokenized_prompt, key, params, top_k, top_p, temperature, condition_scale\n",
    "):\n",
    "    return model.generate(\n",
    "        **tokenized_prompt,\n",
    "        prng_key=key,\n",
    "        params=params,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        temperature=temperature,\n",
    "        condition_scale=condition_scale,\n",
    "    )\n",
    "# decode image\n",
    "@partial(jax.pmap, axis_name=\"batch\")\n",
    "def p_decode(indices, params):\n",
    "    return vqgan.decode_code(indices, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the processor piece by piece\n",
    "\n",
    "from dalle_mini.model.configuration import DalleBartConfig\n",
    "from dalle_mini.model.text import TextNormalizer\n",
    "from dalle_mini.model.tokenizer import DalleBartTokenizer\n",
    "from dalle_mini.model.utils import PretrainedFromWandbMixin\n",
    "\n",
    "tokenizer = DalleBartTokenizer.from_pretrained('dalle-mini/dalle-mega')\n",
    "config = DalleBartConfig.from_pretrained('dalle-mini/dalle-mega')\n",
    "processor = DalleBartProcessor(tokenizer, config.normalize_text, config.max_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all model files (~5 GB)\n",
    "from dalle_mini import DalleBartProcessor\n",
    "\n",
    "processor = DalleBartProcessor.from_pretrained(DALLE_MODEL, revision=DALLE_COMMIT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"fine art painting of a foolish samurai warrior wielding a magic sword stepping forth to oppose the evil that is Aku\",\n",
    "    \"Barack Obama holding up the World Cup trophy\",\n",
    "    \"Obi Wan Kenobi standing over lava with a lightsaber\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_prompts = processor(prompts)\n",
    "tokenized_prompt = replicate(tokenized_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_predictions = 8\n",
    "\n",
    "# We can customize generation parameters (see https://huggingface.co/blog/how-to-generate)\n",
    "gen_top_k = None\n",
    "gen_top_p = None\n",
    "temperature = None\n",
    "cond_scale = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training.common_utils import shard_prng_key\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "print(f\"Prompts: {prompts}\\n\")\n",
    "# generate images\n",
    "images = []\n",
    "for i in trange(max(n_predictions // jax.device_count(), 1)):\n",
    "    # get a new key\n",
    "    key, subkey = jax.random.split(key)\n",
    "    # generate images\n",
    "    encoded_images = p_generate(\n",
    "        tokenized_prompt,\n",
    "        shard_prng_key(subkey),\n",
    "        params,\n",
    "        gen_top_k,\n",
    "        gen_top_p,\n",
    "        temperature,\n",
    "        cond_scale,\n",
    "    )\n",
    "    # remove BOS\n",
    "    encoded_images = encoded_images.sequences[..., 1:]\n",
    "    # decode images\n",
    "    decoded_images = p_decode(encoded_images, vqgan_params)\n",
    "    decoded_images = decoded_images.clip(0.0, 1.0).reshape((-1, 256, 256, 3))\n",
    "    for decoded_img in decoded_images:\n",
    "        img = Image.fromarray(np.asarray(decoded_img * 255, dtype=np.uint8))\n",
    "        images.append(img)\n",
    "        display(img)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
